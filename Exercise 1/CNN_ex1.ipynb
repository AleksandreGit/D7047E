{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def init(self):\n",
    "        super().init()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,activation_function):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 3),#32x32 -> 30x30 (no pad)\n",
    "            activation_function(),\n",
    "            nn.MaxPool2d(2, stride = 2), #2x2 maxpool (devide hight and with by 2 -> 15x15)\n",
    "            nn.Conv2d(6, 10, 3),#(no padding -> 13x13)\n",
    "            activation_function(),\n",
    "        )\n",
    "        self.linear_lay = nn.Sequential(\n",
    "            nn.Linear(1690, 300),# (13X13X10 (outchanels))\n",
    "            activation_function(),\n",
    "            nn.Linear(300, 50),\n",
    "            activation_function(),\n",
    "            nn.Linear(50,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)# this flattens X before linear layer\n",
    "        x = self.linear_lay(x) # bc this is our output layer. No activation here.\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "X_train, X_val= train_test_split(\n",
    "trainset, test_size=0.2, random_state=42)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(X_train, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(X_val, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "import torch\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(train_on_gpu)\n",
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(validationloader))\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.302 10 porcent correct \n",
      "[1,  4000] loss: 2.303 10 porcent correct \n",
      "[1,  6000] loss: 2.302 11 porcent correct \n",
      "[1,  8000] loss: 2.303 11 porcent correct \n",
      "[1, 10000] loss: 2.302 12 porcent correct \n",
      "[2,  2000] loss: 2.302 12 porcent correct \n",
      "[2,  4000] loss: 2.302 12 porcent correct \n",
      "[2,  6000] loss: 2.302 13 porcent correct \n",
      "[2,  8000] loss: 2.302 13 porcent correct \n",
      "[2, 10000] loss: 2.302 12 porcent correct \n",
      "[3,  2000] loss: 2.302 14 porcent correct \n",
      "[3,  4000] loss: 2.302 14 porcent correct \n",
      "[3,  6000] loss: 2.302 14 porcent correct \n",
      "[3,  8000] loss: 2.301 13 porcent correct \n",
      "[3, 10000] loss: 2.301 13 porcent correct \n",
      "[4,  2000] loss: 2.301 14 porcent correct \n",
      "[4,  4000] loss: 2.301 13 porcent correct \n",
      "[4,  6000] loss: 2.301 14 porcent correct \n",
      "[4,  8000] loss: 2.300 13 porcent correct \n",
      "[4, 10000] loss: 2.300 13 porcent correct \n",
      "[5,  2000] loss: 2.299 13 porcent correct \n",
      "[5,  4000] loss: 2.298 14 porcent correct \n",
      "[5,  6000] loss: 2.297 15 porcent correct \n",
      "[5,  8000] loss: 2.296 15 porcent correct \n",
      "[5, 10000] loss: 2.293 16 porcent correct \n",
      "[6,  2000] loss: 2.288 15 porcent correct \n",
      "[6,  4000] loss: 2.282 15 porcent correct \n",
      "[6,  6000] loss: 2.274 17 porcent correct \n",
      "[6,  8000] loss: 2.265 18 porcent correct \n",
      "[6, 10000] loss: 2.255 20 porcent correct \n",
      "[7,  2000] loss: 2.245 21 porcent correct \n",
      "[7,  4000] loss: 2.234 22 porcent correct \n",
      "[7,  6000] loss: 2.221 24 porcent correct \n",
      "[7,  8000] loss: 2.213 24 porcent correct \n",
      "[7, 10000] loss: 2.197 24 porcent correct \n",
      "[8,  2000] loss: 2.204 25 porcent correct \n",
      "[8,  4000] loss: 2.185 25 porcent correct \n",
      "[8,  6000] loss: 2.188 27 porcent correct \n",
      "[8,  8000] loss: 2.176 28 porcent correct \n",
      "[8, 10000] loss: 2.170 28 porcent correct \n",
      "[9,  2000] loss: 2.164 27 porcent correct \n",
      "[9,  4000] loss: 2.160 29 porcent correct \n",
      "[9,  6000] loss: 2.160 29 porcent correct \n",
      "[9,  8000] loss: 2.157 30 porcent correct \n",
      "[9, 10000] loss: 2.149 31 porcent correct \n",
      "[10,  2000] loss: 2.149 31 porcent correct \n",
      "[10,  4000] loss: 2.144 31 porcent correct \n",
      "[10,  6000] loss: 2.142 32 porcent correct \n",
      "[10,  8000] loss: 2.134 31 porcent correct \n",
      "[10, 10000] loss: 2.135 31 porcent correct \n",
      "[11,  2000] loss: 2.129 32 porcent correct \n",
      "[11,  4000] loss: 2.123 31 porcent correct \n",
      "[11,  6000] loss: 2.133 31 porcent correct \n",
      "[11,  8000] loss: 2.132 31 porcent correct \n",
      "[11, 10000] loss: 2.121 32 porcent correct \n",
      "[12,  2000] loss: 2.121 32 porcent correct \n",
      "[12,  4000] loss: 2.117 34 porcent correct \n",
      "[12,  6000] loss: 2.116 32 porcent correct \n",
      "[12,  8000] loss: 2.118 32 porcent correct \n",
      "[12, 10000] loss: 2.115 33 porcent correct \n",
      "[13,  2000] loss: 2.108 33 porcent correct \n",
      "[13,  4000] loss: 2.109 34 porcent correct \n",
      "[13,  6000] loss: 2.107 33 porcent correct \n",
      "[13,  8000] loss: 2.112 36 porcent correct \n",
      "[13, 10000] loss: 2.102 34 porcent correct \n",
      "[14,  2000] loss: 2.103 35 porcent correct \n",
      "[14,  4000] loss: 2.098 34 porcent correct \n",
      "[14,  6000] loss: 2.098 37 porcent correct \n",
      "[14,  8000] loss: 2.094 35 porcent correct \n",
      "[14, 10000] loss: 2.098 36 porcent correct \n",
      "[15,  2000] loss: 2.082 35 porcent correct \n",
      "[15,  4000] loss: 2.092 34 porcent correct \n",
      "[15,  6000] loss: 2.093 34 porcent correct \n",
      "[15,  8000] loss: 2.087 36 porcent correct \n",
      "[15, 10000] loss: 2.091 36 porcent correct \n",
      "[16,  2000] loss: 2.084 38 porcent correct \n",
      "[16,  4000] loss: 2.073 36 porcent correct \n",
      "[16,  6000] loss: 2.078 37 porcent correct \n",
      "[16,  8000] loss: 2.089 36 porcent correct \n",
      "[16, 10000] loss: 2.081 37 porcent correct \n",
      "[17,  2000] loss: 2.075 38 porcent correct \n",
      "[17,  4000] loss: 2.074 37 porcent correct \n",
      "[17,  6000] loss: 2.076 36 porcent correct \n",
      "[17,  8000] loss: 2.076 37 porcent correct \n",
      "[17, 10000] loss: 2.077 38 porcent correct \n",
      "[18,  2000] loss: 2.071 35 porcent correct \n",
      "[18,  4000] loss: 2.066 38 porcent correct \n",
      "[18,  6000] loss: 2.061 37 porcent correct \n",
      "[18,  8000] loss: 2.065 37 porcent correct \n",
      "[18, 10000] loss: 2.082 37 porcent correct \n",
      "[19,  2000] loss: 2.068 37 porcent correct \n",
      "[19,  4000] loss: 2.056 38 porcent correct \n",
      "[19,  6000] loss: 2.057 38 porcent correct \n",
      "[19,  8000] loss: 2.058 38 porcent correct \n",
      "[19, 10000] loss: 2.067 40 porcent correct \n",
      "[20,  2000] loss: 2.052 38 porcent correct \n",
      "[20,  4000] loss: 2.059 38 porcent correct \n",
      "[20,  6000] loss: 2.049 39 porcent correct \n",
      "[20,  8000] loss: 2.054 39 porcent correct \n",
      "[20, 10000] loss: 2.051 40 porcent correct \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "PATH='model.pth'\n",
    "net = CNN(nn.LeakyReLU)\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        writer.add_scalar('Model1 Loss/train', loss.item(), epoch*10000+i) \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            val_loss = validate(net, 1, epoch)\n",
    "            print('[%d, %5d] loss: %.3f %d porcent correct ' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000, val_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.203 27 procent correct \n",
      "[1,  4000] loss: 2.139 32 procent correct \n",
      "[1,  6000] loss: 2.110 34 procent correct \n",
      "[1,  8000] loss: 2.100 35 procent correct \n",
      "[1, 10000] loss: 2.089 37 procent correct \n",
      "[2,  2000] loss: 2.065 40 procent correct \n",
      "[2,  4000] loss: 2.057 39 procent correct \n",
      "[2,  6000] loss: 2.051 40 procent correct \n",
      "[2,  8000] loss: 2.043 39 procent correct \n",
      "[2, 10000] loss: 2.041 42 procent correct \n",
      "[3,  2000] loss: 2.032 44 procent correct \n",
      "[3,  4000] loss: 2.017 42 procent correct \n",
      "[3,  6000] loss: 2.019 42 procent correct \n",
      "[3,  8000] loss: 2.015 43 procent correct \n",
      "[3, 10000] loss: 2.001 42 procent correct \n",
      "[4,  2000] loss: 2.000 43 procent correct \n",
      "[4,  4000] loss: 1.988 44 procent correct \n",
      "[4,  6000] loss: 1.994 47 procent correct \n",
      "[4,  8000] loss: 1.990 43 procent correct \n",
      "[4, 10000] loss: 1.989 45 procent correct \n",
      "[5,  2000] loss: 1.979 48 procent correct \n",
      "[5,  4000] loss: 1.974 47 procent correct \n",
      "[5,  6000] loss: 1.971 49 procent correct \n",
      "[5,  8000] loss: 1.971 48 procent correct \n",
      "[5, 10000] loss: 1.963 47 procent correct \n",
      "[6,  2000] loss: 1.953 50 procent correct \n",
      "[6,  4000] loss: 1.958 48 procent correct \n",
      "[6,  6000] loss: 1.952 48 procent correct \n",
      "[6,  8000] loss: 1.954 48 procent correct \n",
      "[6, 10000] loss: 1.953 51 procent correct \n",
      "[7,  2000] loss: 1.938 50 procent correct \n",
      "[7,  4000] loss: 1.930 50 procent correct \n",
      "[7,  6000] loss: 1.941 50 procent correct \n",
      "[7,  8000] loss: 1.935 51 procent correct \n",
      "[7, 10000] loss: 1.935 50 procent correct \n",
      "[8,  2000] loss: 1.918 50 procent correct \n",
      "[8,  4000] loss: 1.920 49 procent correct \n",
      "[8,  6000] loss: 1.915 51 procent correct \n",
      "[8,  8000] loss: 1.913 51 procent correct \n",
      "[8, 10000] loss: 1.920 52 procent correct \n",
      "[9,  2000] loss: 1.898 51 procent correct \n",
      "[9,  4000] loss: 1.899 53 procent correct \n",
      "[9,  6000] loss: 1.911 52 procent correct \n",
      "[9,  8000] loss: 1.900 53 procent correct \n",
      "[9, 10000] loss: 1.911 53 procent correct \n",
      "[10,  2000] loss: 1.890 52 procent correct \n",
      "[10,  4000] loss: 1.894 54 procent correct \n",
      "[10,  6000] loss: 1.891 52 procent correct \n",
      "[10,  8000] loss: 1.885 52 procent correct \n",
      "[10, 10000] loss: 1.887 54 procent correct \n",
      "[11,  2000] loss: 1.871 54 procent correct \n",
      "[11,  4000] loss: 1.875 52 procent correct \n",
      "[11,  6000] loss: 1.879 53 procent correct \n",
      "[11,  8000] loss: 1.876 53 procent correct \n",
      "[11, 10000] loss: 1.877 54 procent correct \n",
      "[12,  2000] loss: 1.866 53 procent correct \n",
      "[12,  4000] loss: 1.864 54 procent correct \n",
      "[12,  6000] loss: 1.872 55 procent correct \n",
      "[12,  8000] loss: 1.851 54 procent correct \n",
      "[12, 10000] loss: 1.859 54 procent correct \n",
      "[13,  2000] loss: 1.845 55 procent correct \n",
      "[13,  4000] loss: 1.852 55 procent correct \n",
      "[13,  6000] loss: 1.849 55 procent correct \n",
      "[13,  8000] loss: 1.845 55 procent correct \n",
      "[13, 10000] loss: 1.855 53 procent correct \n",
      "[14,  2000] loss: 1.831 54 procent correct \n",
      "[14,  4000] loss: 1.838 55 procent correct \n",
      "[14,  6000] loss: 1.836 54 procent correct \n",
      "[14,  8000] loss: 1.838 56 procent correct \n",
      "[14, 10000] loss: 1.841 56 procent correct \n",
      "[15,  2000] loss: 1.816 53 procent correct \n",
      "[15,  4000] loss: 1.822 56 procent correct \n",
      "[15,  6000] loss: 1.833 56 procent correct \n",
      "[15,  8000] loss: 1.821 54 procent correct \n",
      "[15, 10000] loss: 1.830 56 procent correct \n",
      "[16,  2000] loss: 1.813 55 procent correct \n",
      "[16,  4000] loss: 1.813 56 procent correct \n",
      "[16,  6000] loss: 1.810 57 procent correct \n",
      "[16,  8000] loss: 1.811 55 procent correct \n",
      "[16, 10000] loss: 1.814 56 procent correct \n",
      "[17,  2000] loss: 1.798 55 procent correct \n",
      "[17,  4000] loss: 1.803 56 procent correct \n",
      "[17,  6000] loss: 1.801 55 procent correct \n",
      "[17,  8000] loss: 1.796 56 procent correct \n",
      "[17, 10000] loss: 1.807 57 procent correct \n",
      "[18,  2000] loss: 1.780 55 procent correct \n",
      "[18,  4000] loss: 1.785 56 procent correct \n",
      "[18,  6000] loss: 1.796 56 procent correct \n",
      "[18,  8000] loss: 1.799 57 procent correct \n",
      "[18, 10000] loss: 1.796 58 procent correct \n",
      "[19,  2000] loss: 1.765 58 procent correct \n",
      "[19,  4000] loss: 1.787 58 procent correct \n",
      "[19,  6000] loss: 1.781 56 procent correct \n",
      "[19,  8000] loss: 1.781 57 procent correct \n",
      "[19, 10000] loss: 1.790 58 procent correct \n",
      "[20,  2000] loss: 1.762 58 procent correct \n",
      "[20,  4000] loss: 1.771 57 procent correct \n",
      "[20,  6000] loss: 1.770 61 procent correct \n",
      "[20,  8000] loss: 1.776 57 procent correct \n",
      "[20, 10000] loss: 1.772 59 procent correct \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net2 = CNN(nn.LeakyReLU)\n",
    "net2 = net2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net2.parameters(), lr=0.0001)\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('Model2 Loss/train', loss.item(), epoch*10000+i) \n",
    "        \n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            val_loss = validate(net2, 2, epoch)\n",
    "            print('[%d, %5d] loss: %.3f %d procent correct ' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000, val_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.206 31 procent correct \n",
      "[1,  4000] loss: 2.148 33 procent correct \n",
      "[1,  6000] loss: 2.113 34 procent correct \n",
      "[1,  8000] loss: 2.094 35 procent correct \n",
      "[1, 10000] loss: 2.086 39 procent correct \n",
      "[2,  2000] loss: 2.062 40 procent correct \n",
      "[2,  4000] loss: 2.044 42 procent correct \n",
      "[2,  6000] loss: 2.032 44 procent correct \n",
      "[2,  8000] loss: 2.029 44 procent correct \n",
      "[2, 10000] loss: 2.014 43 procent correct \n",
      "[3,  2000] loss: 2.003 46 procent correct \n",
      "[3,  4000] loss: 1.997 46 procent correct \n",
      "[3,  6000] loss: 1.986 46 procent correct \n",
      "[3,  8000] loss: 1.988 47 procent correct \n",
      "[3, 10000] loss: 1.981 49 procent correct \n",
      "[4,  2000] loss: 1.968 49 procent correct \n",
      "[4,  4000] loss: 1.963 47 procent correct \n",
      "[4,  6000] loss: 1.963 50 procent correct \n",
      "[4,  8000] loss: 1.952 49 procent correct \n",
      "[4, 10000] loss: 1.948 50 procent correct \n",
      "[5,  2000] loss: 1.934 50 procent correct \n",
      "[5,  4000] loss: 1.943 50 procent correct \n",
      "[5,  6000] loss: 1.935 51 procent correct \n",
      "[5,  8000] loss: 1.926 50 procent correct \n",
      "[5, 10000] loss: 1.919 51 procent correct \n",
      "[6,  2000] loss: 1.909 52 procent correct \n",
      "[6,  4000] loss: 1.905 50 procent correct \n",
      "[6,  6000] loss: 1.904 52 procent correct \n",
      "[6,  8000] loss: 1.905 50 procent correct \n",
      "[6, 10000] loss: 1.913 53 procent correct \n",
      "[7,  2000] loss: 1.889 52 procent correct \n",
      "[7,  4000] loss: 1.884 54 procent correct \n",
      "[7,  6000] loss: 1.889 54 procent correct \n",
      "[7,  8000] loss: 1.879 53 procent correct \n",
      "[7, 10000] loss: 1.888 52 procent correct \n",
      "[8,  2000] loss: 1.861 54 procent correct \n",
      "[8,  4000] loss: 1.862 55 procent correct \n",
      "[8,  6000] loss: 1.865 54 procent correct \n",
      "[8,  8000] loss: 1.866 54 procent correct \n",
      "[8, 10000] loss: 1.862 56 procent correct \n",
      "[9,  2000] loss: 1.846 56 procent correct \n",
      "[9,  4000] loss: 1.840 55 procent correct \n",
      "[9,  6000] loss: 1.840 55 procent correct \n",
      "[9,  8000] loss: 1.846 56 procent correct \n",
      "[9, 10000] loss: 1.840 56 procent correct \n",
      "[10,  2000] loss: 1.818 56 procent correct \n",
      "[10,  4000] loss: 1.825 56 procent correct \n",
      "[10,  6000] loss: 1.826 56 procent correct \n",
      "[10,  8000] loss: 1.817 55 procent correct \n",
      "[10, 10000] loss: 1.824 58 procent correct \n",
      "[11,  2000] loss: 1.795 57 procent correct \n",
      "[11,  4000] loss: 1.800 55 procent correct \n",
      "[11,  6000] loss: 1.798 58 procent correct \n",
      "[11,  8000] loss: 1.806 56 procent correct \n",
      "[11, 10000] loss: 1.815 58 procent correct \n",
      "[12,  2000] loss: 1.775 57 procent correct \n",
      "[12,  4000] loss: 1.776 55 procent correct \n",
      "[12,  6000] loss: 1.784 57 procent correct \n",
      "[12,  8000] loss: 1.791 58 procent correct \n",
      "[12, 10000] loss: 1.788 56 procent correct \n",
      "[13,  2000] loss: 1.755 57 procent correct \n",
      "[13,  4000] loss: 1.770 57 procent correct \n",
      "[13,  6000] loss: 1.763 57 procent correct \n",
      "[13,  8000] loss: 1.770 57 procent correct \n",
      "[13, 10000] loss: 1.767 58 procent correct \n",
      "[14,  2000] loss: 1.739 59 procent correct \n",
      "[14,  4000] loss: 1.753 56 procent correct \n",
      "[14,  6000] loss: 1.746 57 procent correct \n",
      "[14,  8000] loss: 1.751 59 procent correct \n",
      "[14, 10000] loss: 1.752 57 procent correct \n",
      "[15,  2000] loss: 1.732 57 procent correct \n",
      "[15,  4000] loss: 1.730 56 procent correct \n",
      "[15,  6000] loss: 1.732 56 procent correct \n",
      "[15,  8000] loss: 1.739 58 procent correct \n",
      "[15, 10000] loss: 1.729 59 procent correct \n",
      "[16,  2000] loss: 1.714 57 procent correct \n",
      "[16,  4000] loss: 1.717 59 procent correct \n",
      "[16,  6000] loss: 1.716 57 procent correct \n",
      "[16,  8000] loss: 1.723 58 procent correct \n",
      "[16, 10000] loss: 1.723 58 procent correct \n",
      "[17,  2000] loss: 1.704 59 procent correct \n",
      "[17,  4000] loss: 1.698 57 procent correct \n",
      "[17,  6000] loss: 1.704 59 procent correct \n",
      "[17,  8000] loss: 1.705 58 procent correct \n",
      "[17, 10000] loss: 1.712 59 procent correct \n",
      "[18,  2000] loss: 1.691 59 procent correct \n",
      "[18,  4000] loss: 1.693 58 procent correct \n",
      "[18,  6000] loss: 1.690 59 procent correct \n",
      "[18,  8000] loss: 1.696 58 procent correct \n",
      "[18, 10000] loss: 1.694 59 procent correct \n",
      "[19,  2000] loss: 1.682 58 procent correct \n",
      "[19,  4000] loss: 1.682 59 procent correct \n",
      "[19,  6000] loss: 1.678 59 procent correct \n",
      "[19,  8000] loss: 1.684 59 procent correct \n",
      "[19, 10000] loss: 1.681 59 procent correct \n",
      "[20,  2000] loss: 1.671 58 procent correct \n",
      "[20,  4000] loss: 1.675 58 procent correct \n",
      "[20,  6000] loss: 1.670 57 procent correct \n",
      "[20,  8000] loss: 1.669 59 procent correct \n",
      "[20, 10000] loss: 1.673 58 procent correct \n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net3 = CNN(nn.Tanh)\n",
    "net3 = net3.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net3.parameters(), lr=0.0001)\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net3(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('Model3 Loss/train', loss.item(), epoch*10000+i) \n",
    "        \n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            val_loss = validate(net3, 3, epoch)\n",
    "            print('[%d, %5d] loss: %.3f %d procent correct ' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000, val_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, modelVal):\n",
    "    true_labels=[]\n",
    "    pred_labels=[]\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            image, label = data\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            pred = model(image)\n",
    "            for i in range(4):\n",
    "                if torch.argmax(pred[i]) == label[i]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "    print(\" predicted = \", correct/total*100, \"% of total \",total)\n",
    "    writer.add_scalar('Model' + str(modelVal) +'/Accuracy/test', correct/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, modelVal, epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validationloader, 0):\n",
    "            image, label = data\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            pred = model(image)\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, label)\n",
    "                         \n",
    "            if torch.argmax(pred[0]) == label[0]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        writer.add_scalar('Model' + str(modelVal) + '/Epoch' + str(epoch) + '/Loss/validation', loss.item())\n",
    "    return(correct/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted =  35.08 % of total  10000\n"
     ]
    }
   ],
   "source": [
    "test(net, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted =  58.650000000000006 % of total  10000\n"
     ]
    }
   ],
   "source": [
    "test(net2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted =  58.3 % of total  10000\n"
     ]
    }
   ],
   "source": [
    "test(net3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
